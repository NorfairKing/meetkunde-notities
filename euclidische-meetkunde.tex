\documentclass[main.tex]{subfiles}
\begin{document}

\chapter{Euclidische meetkunde}
\label{cha:euclidische-meetkunde}

\begin{de}
  Zij $p\in\mathbb{A}^{n}$, $v_{p}$ en $w_{p}$ rakende vectoren in $T_{p}\mathbb{A}^{n}$.
  Het \term{Euclidisch scalair product} $\cdot$ van $v_{p}$ en $w_{p}$ definieren we als volgt:
  \[ v_{p} \cdot w_{p} = \sum_{i=1}^{n}v_{i}w_{i} \]
\end{de}

\begin{ei}
  Distributiviteit ten opzichte van de optelling van vectoren.\\
  Zij $u$, $v$ en $w$ raakvectoren in $T_{p}\mathbb{A}^{n}$ en $a$ en $b$ scalars in $\mathbb{R}$.
  \[ (au + bv) \cdot w = au\cdot w + bv \cdot w \]

  \begin{proof}
    \[
    \begin{array}{rll}
      (au + bv) \cdot w &= \sum_{i=1}^{n}(au + bv)_{i}w_{i} &\\
                        &= \sum_{i=1}^{n}(au_{i} + bv_{i})w_{i} &\\
                        &= \sum_{i=1}^{n}(au_{i}w_{i} + bv_{i}w_{i}) &\\
                        &= \sum_{i=1}^{n}au_{i}w_{i} + \sum_{i=1}^{n}bv_{i}w_{i} &= au\cdot w + bv \cdot w
    \end{array}
    \]
  \end{proof}
\end{ei}

\begin{ei}
  Commutativiteit.\\
  Zij $v$ en $w$ raakvectoren in $T_{p}\mathbb{A}$.
  \[ v\cdot w = w\cdot v\]
  \begin{proof}
    \[ 
    \begin{array}{rll}
      v\cdot w &= \sum_{i=1}^{n}v_{i}w_{i} &\\
               &= \sum_{i=1}^{n}w_{i}v_{i} &= w \cdot v
    \end{array}
    \]
  \end{proof}
\end{ei}

\begin{ei}
  Positiviteit.\\
  Zij $v$ een raakvector in $T_{p}\mathbb{A}$.
  \[ v \cdot v \ge 0 \]

  \begin{proof}
    \[
    v \cdot v =  \sum_{i=1}^{n}v_{i}v_{i} = \sum_{i=1}^{n}v_{i}^{2} \ge 0
    \]
  \end{proof}
\end{ei}

\begin{ei}
  Zij $v$ een raakvector in $T_{p}\mathbb{A}$.
  \[ v \cdot v = 0 \Leftrightarrow v = 0 \]

  \begin{proof}
    \[
    v \cdot v =  \sum_{i=1}^{n}v_{i}v_{i} = \sum_{i=1}^{n}v_{i}^{2} = 0 \Leftrightarrow v = 0
    \]
  \end{proof}
\end{ei}

\begin{de}
  Een \term{Euclidische ruimte} $\mathbb{E}^{n}$ is een affiene ruimte $\mathbb{A}^{n}$, uitgerust met het scalair product $\cdot$.
\end{de}

\begin{de}
  Zij $p\in\mathbb{A}^{n}$, $v_{p}$ een rakende vector in $T_{p}\mathbb{A}^{n}$.
  De \term{lengte} of \term{norm} van $v_{p}$ definieren we als volgt:
  \[ \Vert v_{p} \Vert = \sqrt{v_{p} \cdot v_{p}} = \sqrt{\sum_{i=1}^{n}v_{i}^{2}} \]
\end{de}

\begin{ei}
  Driehoeksongelijkheid.\\
  Zij $v$ en $w$ raakvectoren in $T_{p}\mathbb{A}$.
  \[ \Vert v + w \Vert \le \Vert v \Vert + \Vert w \Vert \]

  \[
  \Vert v + w \Vert
  = \sqrt{\sum_{i=1}^{n}(v+w)_{i}^{2}}
  = \sqrt{\sum_{i=1}^{n}(v_{i}+w_{i})^{2}}
  = \sqrt{\sum_{i=1}^{n}v_{i}^{2}+w_{i}^{2}+ 2v_{i}w_{i}} 
  \le \sqrt{\sum_{i=1}^{n}v_{i}^{2}+w_{i}^{2}} 
  = \Vert v \Vert + \Vert w \Vert
  \]
\end{ei}

\begin{ei}
  \label{ei:ongelijkheid-van-cauchy-schwartz}
  Ongelijkheid van Cauchy-Schwartz\\
  Zij $v$ en $w$ raakvectoren in $T_{p}\mathbb{A}$.
  \[ |v \cdot w| \le \Vert v \Vert \Vert w \Vert \]

  \begin{proof}
    Kies twee vectoren $v$ en $w$ en een scalar $\lambda\in \mathbb{R}$.
    Beschouw nu $(v+\lambda w) \cdot (v + \lambda w)$.
    Dit is zeker positief.
    \[ (v+\lambda w) \cdot (v + \lambda w) = (v \cdot v) + 2 \lambda (v \cdot w) + \lambda^{2}(w \cdot w) \]
    Beschouw bovenstaande gelijkheid als een tweedegraadsveelterm $P$ in $\lambda$ die steeds positief is.
    De discriminant van $P$ is dus negatief.
    \[ 4(v \cdot w)^{2} - 4(v \cdot v)(w \cdot w) \le 0 \]
    \[ \Rightarrow  (v \cdot w)^{2} - (v \cdot v)(w \cdot w) \le 0 \]
    \[ \Leftrightarrow |v \cdot w| - \Vert v \Vert \Vert w \Vert \le 0 \]
    $|v \cdot w|$ is dus kleiner of gelijk aan $\Vert v \Vert \Vert w \Vert$.
  \end{proof}
\end{ei}

\begin{ei}
  Zij $v$ en $w$ raakvectoren in $T_{p}\mathbb{A}$.
  \[ |v \cdot w| = \Vert v \Vert \Vert w \Vert \Leftrightarrow v = \lambda w \]

  \begin{proof}
    Bekijk eerst opnieuw het bewijs van de ongelijkheid van Cauchy-Schwartz.\eiref{ei:ongelijkheid-van-cauchy-schwartz}
    De ongelijkheid wordt een gelijkheid als er een unieke $\lambda$ bestaat zodat $(v+\lambda w) \cdot (v + \lambda w) = 0$ geldt.
    Dit is precies wanneer er een lambda bestaat zodat $v=\lambda w$ geldt.
  \end{proof}
\end{ei}

\begin{de}
  De cosinus van de \term{hoek} $\theta$ tussen twee vectoren $v$ en $w$ met $v$ en $w$ beide niet nul definieren we als volgt:
  \[ v \cdot w = \Vert v \Vert \Vert w \Vert \cos(\theta) \]
\end{de}

\begin{de}
  We noemen twee vectoren $v$ en $w$ \term{orthogonaal} als hun scalair product nul is.
  \[ v \bot w \Leftrightarrow v \cdot w = 0 \]
\end{de}

\begin{de}
  We noemen een basis $v = \{ v_{1}, \dotsc, v_{n} \}$ van een rakende ruimte $T_{p}\mathbb{E}^{n}$ \term{orthogonaal} als de vectoren van $v$ onderling orthogonaal zijn.
\end{de}

\begin{de}
  We noemen een basis $v = \{ v_{1}, \dotsc, v_{n} \}$ van een rakende ruimte $T_{p}\mathbb{E}^{n}$ \term{orthonormaal} als de vectoren van $v$ onderling orthogonaal zijn en lengte $1$ hebben.
\end{de}

\begin{st}
  Zij $v$ een raakvector van $T_{p}\mathbb{E}^{n}$ en $e = \{ e_{1}, \dotsc, e_{n} \}$ een basis van $T_{p}\mathbb{E}^{n}$.
  We noemen het rechterlid de \term{orthonormale expansie} van $v$ ten opzichte van $e$.
  \[ v = \sum_{i=1}^{n} (v \cdot e_{i})e_{i} \]

  \begin{proof}
    $e$ is een basis voor $T_{p}\mathbb{E}^{n}$, dus er bestaan scalars $v_{i}$ zodat $v = \sum_{i=1}^{n}v_{i}e_{i}$ geldt.
    Beschouw nu voor elke $j \in \{ 1,\dotsc,n \}$ $v\cdot e_{j}$
    \[ v \cdot e_{j}
    = \left(\sum_{i=1}^{n}v_{i}e_{i}\right) \cdot e_{j}
    = \sum_{i=1}^{n}v_{i}(e_{i}\cdot e_{j})
    = \sum_{i=1}^{n}v_{i}\delta_{ij} = v_{j}
    \]
  \end{proof}
\end{st}

\begin{gev}
  \label{gev:identiteit-van-parseval}
  De \term{identiteit van Parseval}\\
  Zij $e = \{e_{1},\dotsc,e_{n}\}$ een orthonormale basis van $T_{p}\mathbb{E}^{n}$. 
  \[ v \cdot w = \sum_{i=1}^{n}(v \cdot e_{i})(w \cdot e_{i})\]

  \begin{proof}
    \[
    \begin{array}{rll}

      v \cdot w &= \sum_{i=1}^{n} (v \cdot e_{i})e_{i} \cdot \sum_{j=1}^{n} (w \cdot e_{j})e_{j} &\\ 
                &= \sum_{i=1}^{n}\sum_{j=1}^{n}  (v \cdot e_{i})e_{i} \cdot (w \cdot e_{j})e_{j} &\\
                &= \sum_{i=1}^{n}\sum_{j=1}^{n}  (v \cdot e_{i})e_{i} \cdot e_{j}(w \cdot e_{j}) &\\
                &= \sum_{i=1}^{n}\sum_{j=1}^{n}  (v \cdot e_{i})\delta_{ij}(w \cdot e_{j}) &\\
                &= \sum_{i=1}^{n}(v \cdot e_{i})(w \cdot e_{i})
    \end{array}
    \]
  \end{proof}
\end{gev}

\begin{st}
  Zij $\beta = v_{1},\dotsc,v_{n}$ een basis van $T_{p}\mathbb{E}^{n}$, dan kunnen we $\beta$ omvormen tot een orthonormale basis $\gamma = \{u_1,u_2,\ldots,u_n\}$ door middel van het \term{orthogonalisatieproc\'ed\'e van Gram-Schmidt}

  \begin{proof}
    Bewijs door constructie.\\
    We zullen eenvoudigweg het algoritme beschrijven en de correctheid ervan bewijzen.\\\\
    \begin{itemize}
    \item 
      We normeren de eerste vector $v_1$ door ze te delen door zijn norm.
      \[
      u_1 = \frac{1}{\Vert v_1\Vert}v_1
      \]
      We construeren nu $v_2'$ zodat ze loodrecht staat op $u_1$.
      \[
      v_2' = v_2 - (v_2 \cdot v_1) u_1
      \]
      $v_2'$ is zeker niet nul omdat $u_1$ ofwel niet op dezelfde rechte ligt als $v_2$, ofwel is $v_2' = \vec{0}$. $v_2'$ staat nu wel degelijk loodrecht op $u_1$.
      \[
      \begin{array}{rll}
        v_2' \cdot u_1 &= (v_2 - (v_2 \cdot v_1) u_1) \cdot u_1) &\\
        &= (v_2 \cdot u_1) - ((v_2 \cdot v_1) u_1 \cdot u_1) &\\
        &= (v_2 \cdot u_1) - (v_2 \cdot v_1) (u_1 \cdot u_1) &\\
        &= ( v_2 \cdot u_1) - (v_2 \cdot v_1) \Vert u_1\Vert &\\
        &= (v_2 \cdot u_1) - (v_2 \cdot v_1) &= 0
      \end{array}
      \]
      Merk op dat $u_1$ echt genormeerd moet zijn, opdat dit zou werken. Tenslotte normeren we $v_2'$ nog om $u_2$ te bekomen.
      \[
      u_2 = \frac{1}{\Vert v_2'\Vert}v_2' = \frac{1}{\Vert v_2 - (v_2 \cdot v_1) u_1\Vert}(v_2 - (v_2 \cdot v_1) u_1)
      \]
    \item
      Dit proces kunnen we verder zetten. We beschrijven nu de stappen die je moet ondernemen in iteratie $k+1$.
      We construeren $v_{k+1}'$ als volgt.
      \[
      v_{k+1}' = v_{k+1} - ( v_{k+1}\cdot u_1 ) u_1 - ( v_{k+1}\cdot u_2 )u_2 - \dotsb - (v_{k+1}\cdot u_k ) u_k
      = v_{k+1} - \sum_{i=1}^k (v_{k+1}\cdot u_i)
      \]
      Beschouw de sommatie in deze formule als \'e\'en vector. Nu is de redenering om te besluiten dat $v_{k+1}'$ dezelfde als die bij $v_2'$.
      $v_{k+1}'$ is staat inderdaad loodrecht op alle vectoren $v_i$ met $i\le k$.

      \[
      \begin{array}{rll}
        (v_{k+1}' \cdot u_i) &= \left( v_{k+1} - \sum_{j=1}^k (v_{k+1} \cdot u_j)u_j\right) \cdot u_i &\\
                            &= (v_{k+1} \cdot u_i) - \left( \sum_{j=1}^k (v_{k+1} \cdot u_j)u_j\right) \cdot u_{i} &\\
                            &= (v_{k+1} \cdot u_i) - \sum_{j=1}^k \left((v_{k+1} \cdot u_j) u_j \right) \cdot u_i &\\
                            &= ( v_{k+1} \cdot 3u_i ) - \sum_{j=1}^k (v_{k+1} \cdot u_j ) ( u_j \cdot u_i)
      \end{array}
      \]
      In de laatste som is elke term behalve de term waarbij $i=j$ geldt nul.
      \[
      (v_{k+1},u_i) - (v_{k+1},u_i) = 0
      \]
      We kunnen nu $v_{k+1}'$ ook normeren door te delen door de norm.
      \[
      u_{k+1} = \frac{1}{\Vert v_{k+1}'\Vert}v_{k+1}'
      \]
    \item
      Omdat $V$ eindig dimensionaal is zal dit algoritme zeker stoppen. Het resultaat is $\{u_1,u_2,\ldots,u_n\}$, een orthonormale basis.
    \end{itemize}
  \end{proof}
\end{st}

\begin{de}
  Zij $p$ en $q$ twee punten van $\mathbb{E}^{n}$, dan defini\"eren we de \term{afstand} tussen $p$ en $q$ als $d(p,q)$.
  \[ d(p,q) = \Vert \overline{pq} \Vert = \Vert p-q \Vert \]
\end{de}

\begin{ei}
  \label{ei:symmetrie-afstand}
  Symmetrie van de afstand\\
  Zij $p$ en $q$ twee punten van $\mathbb{E}^{n}$.
  \[ d(p,q) = d(q,p) \]

  \begin{proof}
    \[ d(p,q) = \Vert p-q \Vert = \sqrt{\sum_{i=1}^{n}(p-q)^{2}_{i}} = \sqrt{\sum_{i=1}^{n}(q-p)^{2}_{i}} = \Vert q-p \Vert = d(q,p) \]
  \end{proof}
\end{ei}

\begin{ei}
  \label{ei:afstand-positief}
  Positiviteit van de afstand.
  Zij $p$ en $q$ twee punten van $\mathbb{E}^{n}$
  \[ d(p,q) \ge 0 \]

  \begin{proof}
    \[ d(p,q) = \Vert p-q \Vert = \sqrt{\sum_{i=1}^{n}(p-q)^{2}_{i}} \ge 0 \]
    Elke term in de som is positief, want het zij kwadraten.
    De wortel is dus zinvol en natuurlijk ook positief.
  \end{proof}
\end{ei}

\begin{ei}
  \label{ei:afstand-nul-gelijk}
  Zij $p$ en $q$ twee punten van $\mathbb{E}^{n}$
  \[ d(p,q) = 0 \Leftrightarrow p = q \]

  \begin{proof}
    \[ d(p,q) = \Vert p-q \Vert = \sqrt{\sum_{i=1}^{n}(p-q)^{2}_{i}} = 0 \Leftrightarrow p = q \]
  \end{proof}
\end{ei}

\begin{ei}
  \label{ei:driehoeksongelijkheid-in-En}
  Driehoeksongelijkheid in $\mathbb{E}^{n}$.
  \[ d(p,r) \le d(p,q) + d(q,r) \]
\extra{bewijs}
\end{ei}

\section{Euclidische transformaties}
\label{sec:eucl-transf}

\begin{de}
  \label{de:euclidische-transformatie}
  Een affiene transformatie $F$ met lineair deel $A$ en translatiedeel $b$ noemen we een \term{Euclidische transformatie} of een \term{isometrie van de Euclidische ruimte} als en slechts als $A$ een orthogonale transformatie is.
  \[ A \in O(n) = \{ X \in GL(n,\mathbb{R}^{n}) \ |\ X^{T}X = I \} \]
\end{de}

\subsection{Orthogonale transformaties}
\label{sec:orth-transf}

\begin{st}
  \label{st:i-orthogonaal}
  \[ \mathbb{I}_{n} \in O(n) \] 

  \begin{proof}
    \[ \mathbb{I}_{n}^{T}\mathbb{I}_{n} = \mathbb{I}_{n}\mathbb{I}_{n} = \mathbb{I}_{n} \]
  \end{proof}
\end{st}

\begin{st}
  \label{st:product-orthogonale-matrices-orthogonaal}
  Het product van twee orthogonale matrices is een orthogonale matrix.

  \begin{proof}
    Zij $X$ en $Y$ twee orthogonale matrices met dezelfde dimensies $n \times n$.
    \[
    \begin{array}{rll}
      (XY)^{T}(XY) &= Y^{T}X^{T}XY &\\
                  &= Y^{T}\mathbb{I}_{n}Y &\\
                  &= Y^{T}Y &= \mathbb{I}_{n}
    \end{array}
    \]
    $XY$ is dus ook een orthogonale matrix.
  \end{proof}
\end{st}

\begin{st}
  \label{st:inverse-orthogonale-matrix-orthogonaal}
  Zij $X$ een orthogonale matrix, dan is ook $X^{T}=X^{-1}$ orthogonaal.
  \[ X \in O(n) \Leftrightarrow X^{T} = X^{-1} \in O(n)\]

  \begin{proof}
    Zij $X$ een orthogonale $n\times n$ matrix.
    \[ (X^{T})^{T}X^{T} = XX^{T} = XX^{-1} = \mathbb{I}_{n} \]
  \end{proof}
\end{st}

\begin{st}
  $O(n)$ is een deelgroep van $GL(n,\mathbb{R})$

  \begin{proof}
    We gaan elke eigenschap in het criterium van een deelgroep na.
    \begin{itemize}
    \item $\mathbb{I}_{n}$, het neutraal element van $GL(n,\mathbb{I}_{n})$ is een element van $O(n)$.\stref{st:i-orthogonaal}
    \item Het product van twee orthogonale matrices is orthogonaal.\stref{st:product-orthogonale-matrices-orthogonaal}
    \item De inverse van een orthogonale matrix is ortogonaal.\stref{st:inverse-orthogonale-matrix-orthogonaal}
    \end{itemize}
  \end{proof}
\end{st}

\begin{de}
  $O(n)$ noemt men de \term{orthogonale groep}.
\end{de}

\begin{st}
  De verzameling van alle orthonale matrices met positieve determinant (determinant $1$) is een deelgroep van $O(n)$.

  \begin{proof}
    We gaan elke eigenschap in het criterium van een deelgroep na.
    \begin{itemize}
    \item $\mathbb{I}_{n}$, het neutraal element van $O(n)$ heeft determinant $1$.
    \item Het product van twee matrices met determinant $1$ heeft determinant $1$.
      Zij $A$ en $B$ twee matrices met determinant $1$:
      \[ |AB| = |A||B| = 1\cdot 1 = 1 \]
    \item De inverse van een matrix met determinant heeft determinant $1$.
      Zij immers $A$ een matrix met determinant $1$.
      \[ |A^{-1}| = |A^{T}| = |A| \]
    \end{itemize}
  \end{proof}
\end{st}

\begin{de}
  De groep van alle orthogonale matrices met determinant $1$ wordt de \term{speciale orthogonale groep} genoemd.
\end{de}

\begin{st}
  Zij $v$ en $w$ twee kolomvectoren uit $\mathbb{R}^{n}$ en $X \in GL(n,\mathbb{R})$ een orthogonale vierkante matrix.
  \[ \forall v,w \in \mathbb{R}^{n}:\ (Xv)\cdot(Xw) = v \cdot w \Leftrightarrow X \in O(n) \]

\extra{bewijs}
\[ (Xv) \cdot (Xw) = (Xv)^{T}(Xw) = v^{T}X^{T}Xw = v^{T}(XX^{T})w \]
\end{st}

\begin{st}
  Ortogonale transformaties bewaren de norm van een vector.
\end{st}

\begin{de}
  Orthogonale matrices zijn matrices waarvan de kolommon (en dus ook de rijen) een orthogonale basis vormen.
\end{de}

\begin{st}
  Zij $X\in O(n)$ een ortogonale matrix en $\lambda\in \mathbb{R}$ een eigenwaarde van $X$, dan bestaat er een vector $v\neq \vec{0}$ zodat $Xv = \lambda v$.
  $\lambda$ moet dan $1$ of $-1$ zijn: $ \Vert v \Vert^{2} = \Vert X v \Vert^{2} = \lambda^{2}\Vert v\Vert^{2}$
  Als $v$ een eigenvector is met eigenwaarde $1$, en $w$ een eigenvector met eigenwaarde $-1$, dan zijn $v$ en $w$ orthogonaal: $v \bot w$
  want $v \cdot w = Xv \cdot Xw = -v \cdot w$.
\extra{bewijs, zie spectraalstelling bij LA en definitie eigenwaarde. scheiden in apparte stellingen etc}
\end{st}

\begin{de}
  Zij $X$ een lineaire transformatie van $\mathbb{R}^{n}$, dan noemen we een linearie deelruimte $V$ van $\mathbb{R}^{n}$ \term{invariant onder een lineaire transformatie} $X$ als voor alle $v\in V$ $Xv \in V$ geldt.
\end{de}

\begin{de}
  Zij $V$ en $W$ twee lineaire deelruimten van een vectorruimte $U$ en $V$ een deelruimte van $W$.
  Het \term{orthogonaal complement} $V^{\bot}$ van $V$ ten opzichte van $W$ is de ruimte van alle vectoren $w\in W$ die loodrecht staan op alle vectoren in $V$.
  \[ V^{\bot}_{W} = \{ w \in W\ |\ \forall v \in V:\ w \bot v \} \]
\end{de}

\begin{st}
  Zij $V$ en $W$ twee lineaire deelruimten van een vectorruimte $U$ en $V$ een deelruimte van $W$.
  \[ dim(V) + dim(V^{\bot}_{W}) = dim(W) \]
  \extra{bewijs}
\end{st}

\begin{st}
  Zij $V$ een lineaire deelruimte van een vectorruimte $U$.
  Zij $X$ een orthogonale transformatie van $U$.
  \[ V \text{ is invariant onder } X \Leftrightarrow V^{\bot}_{U} \text{ is invariant onder } X \]
\extra{bewijs, zie ook p 82}
\end{st}

\subsection{Euclidische invarianten en afstand}
\label{sec:eucl-invar-en}

\begin{st}
  Een affiene transformatie $F$ is een isometrie als en slechts als volgende bewering geldt:
  \[ \forall v,w:\ F_{*}v \cdot F_{*}w = v \cdot w \]
\extra{bewijs}
\end{st}

\begin{st}
  Elke traslatie is een isometrie.
\extra{bewijs}
\end{st}

\begin{st}
  Elke orthogonale transformatie is een isometrie.
\extra{bewijs}
\end{st}

\begin{st}
  De samenstelling van twee isometrie\"en is oon isometrie.
\extra{bewijs}
\end{st}

\begin{st}
  De inverse van een isometrie is een isometrie.
\extra{bewijs}
\end{st}

\begin{de}
  De verzameling van alle isometrie\"en van $\mathbb{E}^{n}$ wordt genoteerd als $Iso(n,\mathbb{R})$.
\end{de}

\begin{st}
  $Iso(n,\mathbb{R}),\circ$ is een groep.
\end{st}

\begin{de}
  $Iso(n,\mathbb{R}),\circ$ noemt men soms de \term{Euclidische groep}.
\end{de}

\begin{de}
  De verzameling van orientatiebewarende isometrie\"en noteren we als $Iso^{+}(n,\mathbb{R})$ en de verzameling van orientatieomkerende isometrie\"en noteren we als $Iso^{-}(n,\mathbb{R})$.
\end{de}

\begin{st}
  $\{ Iso^{+}(n,\mathbb{R}), Iso^{-}(n,\mathbb{R} \}$ is een partitie van ...
\extra{bewijs}
\end{st}

\begin{de}
  Een eigenschap noemen we \term{Euclidisch invariant} als de eigenschap invariant is onder isometrie\"en.
\end{de}

\begin{st}
  Het volume van een basis is, op teken na een Euclidische invariant.
\extra{bewijs}
\end{st}

\begin{st}
  Elke affiene invariant is ook een euclidische invariant.
\extra{bewijs}
\end{st}

\begin{st}
  Het scalair product van twee vectoren is een Euclidische invariant.
\extra{bewijs}
\[ F_{*}v \cdot F_{*}w = v \cdot w \]
\end{st}

\begin{st}
  De ortogonale stand van vectoren is een euclidische invariant.
\extra{bewijs}
\end{st}

\begin{st}
  De lengte van vectoren is een Euclidische invariant.
\extra{bewijs}
\[ \forall v:\ \Vert F_{*}v \Vert = \sqrt{F_{*}v \cdot F_{*}v} = \Vert v \Vert \]
\end{st}

\begin{st}
  De afstand tussen twee punten is een Euclidische invariant.
\extra{bewijs}
\[ d(F(p),F(q)) = \Vert \overrightarrow{F(p)F(q)} \Vert = \Vert F_{*}(\overrightarrow{pq}) \Vert = \Vert \overrightarrow{pq} \Vert = d(p,q) \]
\end{st}

\begin{st}
  Zij $F:\ \mathbb{E}^{n}\rightarrow \mathbb{E}^{n}$ een willekeurige afbeelding die de afstand tussen twee punten bewaart, dan is $F$ een isometrie.
  \[ \forall p,q \in \mathbb{E}^{n}:\  d(F(p),F(q)) = d(p,q) \]
\TODO{bewijs p 83}
\end{st}

\subsection{Bestaan van isometrie\"en}
\label{sec:best-van-isom}

\begin{st}
  Zij $p$ en $q$ twee punten van $\mathbb{E}^{n}$ en zij $\{ v_{1},\dotsc,v_{n} \}$ een orthonormale basis van $T_{p}\mathbb{E}^{n}$ en $\{ w_{1},\dotsc,w_{n} \}$ een orthonormale basis van $T_{q}\mathbb{E}^{n}$, dan bestaat er een unieke isometrie $F$ van $\mathbb{E}^{n}$ zodat:
  \begin{itemize}
  \item $F(p) = q$
  \item $\forall i:\ F_{*}v_{i} = w_{i}$
  \end{itemize}
\TODO{bewijs p 85}
\end{st}

\begin{gev}
  Zij $a$, $b$, $a'$ en $b'$ vier punten in $\mathbb{E}^{2}$ zodat $d(a,b) = d(a',b') \neq 0$ geldt, dan bestaat er juist \'e\'en orientatiebewarende isometrie $F$ van $\mathbb{E}^{2}$ zodat $F(a) = a'$ en $F(b) = b'$ gelden alsook juist \'e\'e orientatieomkerende isometrie $F$ van $\mathbb{E}^{2}$ met dezelfde eigenschap.
\TODO{bewijs p 85}
\end{gev}

\subsection{Deelruimten van de Euclidische ruimte}
\label{sec:deelruimten-van-de}

\begin{de}
  Twee affiene deelruimten $S=p+V$ en $T=q+W$ van $\mathbb{E}^{n}$ noemen we \term{orthogonaal} als en slechts als $V$ en $W$ ortogonaal zijn:
  \[ S \bot T \Leftrightarrow V \bot W \Leftrightarrow \forall v \in V, w \in W:\ v \bot w \]
\end{de}

\begin{st}
  Zij $S$ een affiene deelruimte van $\mathbb{E}^{n}$ en $x\in \mathbb{E}^{n}$ een punt(?!), dan bestaat er precies \'e\'en affiene deelruimte $T$ door $x$ die orthogonaal complementair is met $S$.
  $S$ en $T$ snijden elkaar bovendien in precies \'e\'en punt $y$:
  \[ d(x,y) = inf\{ d(x,z) \ |\ z \in S  \} \]
\TODO{bewijs p 86}
\end{st}

\begin{de}
  De \term{afstand} tussen een punt $x\in ...$ en een affiene deelruimte $S$ van $\mathbb{E}^{n}$ noteren we als $d(x,S)$.
  \[ d(x,S) = inf\{ d(x,z)\ |\ z \in S \} \]
\end{de}

\begin{de}
  De \term{afstand} tussen twee affiene deelruimten $S$ en $T$ van $\mathbb{E}^{n}$ noteren we als $d(S,T)$.
  \[ d(S,T) = inf\{ d(s,t) \ |\ s\in S, t\in T \} \]
\end{de}

\begin{st}
  Zij $\{u_{1}, \dotsc, u_{n-k}\}$ een orthonormale basis is van $V^{\bot}$
  \[ \forall i \in \{ 1, \dotsc, n-k \} :\ x \in S \Leftrightarrow \overrightarrow{px} \in V \Leftrightarrow \overrightarrow{px} \bot V^{\bot} \Leftrightarrow \overrightarrow{px} \cdot u_{i} = 0 \]
\extra{bewijs}
\end{st}

\begin{st}
  Zij $S=p+V$ een $k$-dimensionale affiene deelruimte van $\mathbb{E}^{n}$, dan is de dimensie van $V^{\bot}$ $n-k$.
\extra{bewijs}
\end{st}

\begin{gev}
  Het ortogonaal complement van een hypervlak is \'e\'endimensionaal.
\extra{bewijs}
\end{gev}

\begin{de}
  De vergelijkingen $\overrightarrow{px} \cdot u_{i} = 0$ of $(x-p) \cdot u_{i} = 0$ noemen we de carthesische vergelijkingen van $S$. Elke vergelijking $(x-p)\cdot u_{i} = 0$ appart stelt een hypervlak voor met richtingsgetallen $u_{i}$ en deze zijn lineair onafhankelijk.
\end{de}

\begin{de}
  Zij $\{u\}$ een basis van $V^{\bot}$ met \'e\'en elemen, dan noemen we $u$ een \term{normaal} op $S$.
\end{de}

\begin{de}
  Zij $u$ een normaal van lengte $1$, dan noemen we $u$ een \term{eenheidsnormaal}.
\end{de}

\begin{st}
  De vergelijking van een hypervlak $S$ door een punt $p$ ziet er als volgt uit, wanneer $u$ een (eenheids?!)normaal is.
  \[ x \in S \Leftrightarrow (x-p) \cdot u = 0 \]
\extra{bewijs, wut}
\end{st}

\begin{gev}
  Het richtingsgetal van een hypervlak $S$ is de normaal op $S$
\extra{bewijs, wut}
\end{gev}


\end{document}
